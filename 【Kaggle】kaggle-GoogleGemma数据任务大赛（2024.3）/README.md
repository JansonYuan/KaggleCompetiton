# 【Kaggle】kaggle-GoogleGemma数据任务大赛

说明：本项目中包含了部分方案解析、录播课件、baseline、以及推荐资料等，欢迎大家关注点赞+收藏！！！

比赛名称：kaggle-GoogleGemma数据任务大赛

比赛链接：https://www.kaggle.com/competitions/data-assistants-with-gemma

比赛任务：你的任务是利用 **Gemma** 模型，构建能够协助进行**数据任务**的 AI 助手。

![CleanShot 2025-09-05 at 16.27.12@2x](/Users/apple/Downloads/【Kaggle】kaggle-GoogleGemma数据任务大赛（2024.3）/assets/CleanShot 2025-09-05 at 16.27.12@2x.png)

![CleanShot 2025-09-05 at 15.48.26@2x](/Users/apple/Downloads/【Kaggle】 Optiver - Trading at the close（2023.10）/assets/CleanShot 2025-09-05 at 15.48.26@2x.png)

---

<img src="assets/20250904_174246_5b2bcaaac91a0105f71ca56604b8dcb5.png" style="width:500px;" />

欢迎大家了解我们深度之眼，希望能够给大家带去最实用的知识：

https://deepshare.feishu.cn/wiki/Tb7IwetysiLErGk3NQwcQdHznPb?from=from_copylink

---

## 1、比赛简介

谷歌于 2024 年 2 月发布了开源大语言模型 **Gemma**。该模型采用了与谷歌强大模型 Gemini 相同的研究和技术，提供了 **20 亿参数（Gemma 2B）** 和 **70 亿参数（Gemma 7B）** 两种规模，并分为预训练和指令微调两个版本。其中，20 亿参数版本甚至可以直接在笔记本电脑上运行。据官方宣称，70 亿参数版本在多项语言理解、推理、数学等标准测试上表现优异，击败了主流开源模型 Llama-2 和 Mistral。

## **2、时间安排**

2024 年 2 月  21 日 - 比赛开始日期

2024 年 4 月  15 日 - 比赛结束日期

## **3、整个课程的讲解思路和讲课逻辑是怎么样的？**

**1. 核心任务**

这是一个**开源大语言模型（Gemma）的应用与创新竞赛**。重点不在于从零开始训练新模型，而在于如何**有效地使用、微调（fine-tuning）或构建应用层**来充分发挥 Gemma 模型的能力，解决数据任务中的实际问题。

**2. 面向实操**

重点在于掌握 **Gemma 模型的使用方式**（如通过 Kaggle 提供的环境或 Hugging Face Transformers 库）、**提示工程（Prompt Engineering）**、**可能的微调技巧**以及**构建端到端的应用流程**。

**3. 关键挑战**

- **理解 Gemma 的特性**：熟悉 Gemma 模型的强项和弱项，以便设计最有效的应用场景。
- **提示设计**：如何设计精准、高效的提示（Prompt）来引导 Gemma 生成高质量、符合需求的数据任务代码或建议。
- **评估实用性**：如何衡量你构建的 AI 助手对数据任务的实际帮助程度。
- **创新性**：提出独特且有价值的应用点，避免简单的通用对话。

**4. 优化路径**

从**探索 Gemma 模型的基本能力**开始，**构思具体的数据任务辅助场景**，然后通过**迭代优化提示或微调策略**来提升助手的性能和可靠性，最终**封装或展示成一个完整的工具或流程**。

**第 01 课：比赛介绍与 Gemma 模型入门**

**核心内容**

1. **比赛背景**
   - **目标**：鼓励开发者利用谷歌开源的 Gemma 模型，构建创新性的 AI 助手来帮助数据科学家和开发者更高效地完成数据任务。
   - **任务**：使用 Gemma 模型完成与数据任务相关的文本生成或工具构建。
   - **评价指标**：请务必仔细阅读竞赛主页的 Evaluation 部分，了解具体的评分规则。
2. **Gemma 模型概览**
   - **模型访问**：开发者可以在 **Kaggle** 或 **Hugging Face** 等平台上免费访问和使用 Gemma 模型。在 Kaggle 上首次使用可能需要接受许可协议并请求访问权限。
   - **模型规格**：主要提供 **2B（20 亿参数）** 和 **7B（70 亿参数）** 两种尺寸，各有预训练和指令微调版本。2B 版本非常适合在资源有限的环境（如笔记本电脑）进行实验和部署。
   - **技术支持**：谷歌提供了工具包来支持开发者创新和使用 Gemma 模型，并强调了负责任的使用。
3. **Baseline 思路**
   - **基础应用**：使用 Gemma 的指令微调版本，通过设计好的 Prompt 直接让其生成数据清洗、可视化或建模的代码片段。
   - **环境搭建**：在 Kaggle Notebooks 中配置使用 Gemma 所需的环境，例如安装相关的库（如 keras-nlp, transformers），并正确加载模型。

**第 02 课：提示工程与任务设计**

**核心内容**

1. **提示工程（Prompt Engineering）**
   - 这是本次竞赛的**核心技巧**。精心设计的 Prompt 能极大提升 Gemma 输出的质量和准确性。
   - **明确指令**：在 Prompt 中清晰说明任务背景、输入数据格式、期望输出（例如：“请为 Pandas DataFrame df 编写代码，绘制 ‘price’ 列的箱线图，并检测异常值。”）。
   - **提供示例（Few-shot Learning）**：在 Prompt 中给出 1-2 个输入输出示例，引导模型更好地理解你的需求。
   - **迭代优化**：根据模型初始输出的不足，不断调整和细化你的 Prompt。
2. **数据任务场景设计**
   - 思考数据工作流中哪些环节耗时费力或容易出错，Gemma 助手可以在这些环节提供帮助。
   - **代码生成**：如生成数据预处理、特征工程、模型训练、可视化绘图（Matplotlib/Seaborn）的代码。
   - **代码解释与调试**：解释一段复杂数据操作代码的功能，或帮助诊断代码错误。
   - **思路建议**：针对一个数据问题，提供解决思路和步骤建议。
   - **文档生成**：为数据处理流程或机器学习模型生成简要的文档说明。

**第 03 课：模型微调与进阶应用**

**核心内容**

1. **监督微调（SFT）**
   - 如果竞赛允许且基础 Prompt 工程达不到理想效果，可以考虑使用提供的训练数据对 Gemma 模型进行**监督微调（Supervised Fine-Tuning）**。
   - 这需要准备高质量的输入-输出配对数据（例如：{“instruction”: “请标准化 df 中的 ‘age’ 列”, “response”: “from sklearn.preprocessing import  StandardScaler\nscaler = StandardScaler()\ndf['age_scaled'] =  scaler.fit_transform(df[['age']])”}）。
   - 谷歌提到通过原生 Keras 3.0 为所有主要框架（JAX、PyTorch 和 TensorFlow）提供了推理和监督微调（SFT）的工具链。
2. **构建完整应用**
   - **交互式工具**：可以尝试构建一个简单的 Web 界面（例如使用 Gradio 或 Streamlit），用户输入任务描述，后端调用 Gemma 模型并返回结果。
   - **Notebook 插件/魔法命令**：构思一种方式，让在 Kaggle Notebooks 中能更方便地调用你设计的 Gemma 助手。

**第 04 课：集成、优化与负责任地创新**

**核心内容**

1. **性能与优化**
   - **模型选择**：在效果和效率间权衡。2B 模型更快更轻量，7B 模型可能能力更强。根据任务复杂度选择。
   - **推理优化**：关注推理速度，确保用户体验流畅。
2. **负责任 AI**
   - 谷歌发布了“负责任生成 AI 工具包”，为使用 Gemma 等开放模型提供了资源，包括设定安全政策、安全调整、安全分类器和模型评估的指导。
   - 在设计和应用你的 AI 助手时，应考虑其输出结果的**安全性**、**可靠性**和**潜在偏见**。
3. **创新性与实用性**
   - 竞赛鼓励**创新**。思考你的助手是否解决了真实痛点，是否提供了与众不同的价值。
   - **注重实用性**：一个好的助手应该能准确理解需求，生成可用、可运行的代码或提供切实可行的建议。

**第 05 课：往届经验与避坑指南**

**核心内容**

1. **常见陷阱**
   - **Prompt 过于模糊**：导致模型输出不相关或质量低下。
   - **忽视评估指标**：没有严格按照竞赛的评估标准来优化方案。
   - **复杂度与实用性失衡**：想法很复杂，但实际帮助不大，或难以使用。
2. **成功关键**
   - **深刻理解需求**：精准定位数据工作者在哪些环节需要帮助。
   - **熟练掌握 Gemma**：充分了解模型能力边界，善用提示工程和微调。
   - **简洁有效**：解决方案不一定复杂，但应直接有效。
   - **良好展示**：清晰说明你的助手如何工作、解决了什么问题、有何优势。

---

说明：需要课程回放的同学可以扫码，凭点赞截图找小享免费领取哦！！！

<img src="assets/20250904_172853_image.png" style="width:200px;" />
