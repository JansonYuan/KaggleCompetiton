{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 9.086974,
     "end_time": "2024-06-29T23:17:46.466572",
     "exception": false,
     "start_time": "2024-06-29T23:17:37.379598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:albumentations.check_version:Error fetching version info\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/http/client.py\", line 1455, in connect\n",
      "    self.sock = self._context.wrap_socket(self.sock,\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/ssl.py\", line 1104, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/ssl.py\", line 1375, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: _ssl.c:990: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/check_version.py\", line 29, in fetch_version_info\n",
      "    with opener.open(url, timeout=2) as response:\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/data/guanghan/miniconda3/envs/kaggle/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:990: The handshake operation timed out>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, GroupKFold\n",
    "#from timm.data.auto_augment import auto_augment_transform\n",
    "from torchvision import datasets, transforms\n",
    "import albumentations as A\n",
    "# For Image Models\n",
    "import timm\n",
    "from glob import glob\n",
    "# Albumentations for augmentations\n",
    "#import albumentations as A\n",
    "#from albumentations.pytorch import ToTensorV2\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.utils import ModelEmaV2\n",
    "from libauc.sampler import DualSampler  # data resampling (for binary class)\n",
    "from models import ClassifierNet\n",
    "import cv2\n",
    "\n",
    "from apex import amp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwhhhhh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834d1966b58440e4b520538686833a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111223968780703, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/guanghan/isic-2024/wandb/run-20240815_080750-4vpzuu2q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/whhhhh/isic_2024/runs/4vpzuu2q' target=\"_blank\">atomic-sunset-111</a></strong> to <a href='https://wandb.ai/whhhhh/isic_2024' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/whhhhh/isic_2024' target=\"_blank\">https://wandb.ai/whhhhh/isic_2024</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/whhhhh/isic_2024/runs/4vpzuu2q' target=\"_blank\">https://wandb.ai/whhhhh/isic_2024/runs/4vpzuu2q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/whhhhh/isic_2024/runs/4vpzuu2q?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f873f87ee90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# 初始化 Weights & Biases\n",
    "wandb.init(project=\"isic_2024\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.07116,
     "end_time": "2024-06-29T23:17:46.571192",
     "exception": false,
     "start_time": "2024-06-29T23:17:46.500032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 10,\n",
    "    \"img_size\": 384,\n",
    "    \"model_name\": \"tf_efficientnetv2_l.in21k\",\n",
    "    \"checkpoint_path\" : \"./resnet18_pretrained/fold_0_AUROC0.1374_Loss0.1938_epoch8.bin\",\n",
    "    'output_dir': 'resnet18_exp1',\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 32,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"min_lr\": 1e-7,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 0,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"undersample_rate\": 20,\n",
    "    'using_mix_up':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010587,
     "end_time": "2024-06-29T23:17:46.59285",
     "exception": false,
     "start_time": "2024-06-29T23:17:46.582263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.021715,
     "end_time": "2024-06-29T23:17:46.625274",
     "exception": false,
     "start_time": "2024-06-29T23:17:46.603559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 7.631613,
     "end_time": "2024-06-29T23:17:58.409773",
     "exception": false,
     "start_time": "2024-06-29T23:17:50.77816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2024 = pd.read_csv(f\"./2024/train-metadata.csv\")\n",
    "df_2024['file_path'] = df_2024['isic_id'].apply(lambda x:f'./2024/train-image/image/{x}.jpg')\n",
    "#df_2024 = df_2024[['patient_id', 'isic_id', 'target', 'file_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.read_csv(\"./2020/train-metadata.csv\")\n",
    "df_2020['file_path'] = df_2020['isic_id'].apply(lambda x:f'./2020/train-image/image/{x}.jpg')\n",
    "df_2020 = df_2020[['patient_id', 'isic_id', 'target', 'file_path']]\n",
    "\n",
    "df_2019 = pd.read_csv(\"./2019/train-metadata.csv\")\n",
    "df_2019['file_path'] = df_2019['isic_id'].apply(lambda x:f'./2019/train-image/image/{x}.jpg')\n",
    "df_2019 = df_2019[['patient_id', 'isic_id', 'target', 'file_path']]\n",
    "\n",
    "df_2018 = pd.read_csv(\"./2018/train-metadata.csv\")\n",
    "images_path = glob('./2018/train-image/image/*.jpg')\n",
    "df_2018['file_path'] = df_2018['isic_id'].apply(lambda x:f'./2018/train-image/image/{x}.jpg')\n",
    "df_2018 = df_2018[['patient_id', 'isic_id', 'target', 'file_path']]\n",
    "df_2018 = df_2018[df_2018['file_path'].isin(images_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_2024 #pd.concat([df_2020, df_2019, df_2018]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>file_path</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>tbp_lv_Aext</th>\n",
       "      <th>tbp_lv_B</th>\n",
       "      <th>tbp_lv_Bext</th>\n",
       "      <th>...</th>\n",
       "      <th>tbp_lv_symm_2axis_angle</th>\n",
       "      <th>tbp_lv_x</th>\n",
       "      <th>tbp_lv_y</th>\n",
       "      <th>tbp_lv_z</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_location</th>\n",
       "      <th>tbp_lv_location_simple</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_0015670.jpg</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.851095</td>\n",
       "      <td>-0.102881</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>-0.247862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>-0.183826</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_0015845.jpg</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.992701</td>\n",
       "      <td>0.349720</td>\n",
       "      <td>0.494297</td>\n",
       "      <td>-0.016605</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371429</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.787694</td>\n",
       "      <td>0.142046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_0015864.jpg</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.824818</td>\n",
       "      <td>-0.010870</td>\n",
       "      <td>0.136977</td>\n",
       "      <td>0.406357</td>\n",
       "      <td>0.239195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.207932</td>\n",
       "      <td>0.717163</td>\n",
       "      <td>0.717002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_0015902.jpg</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.837956</td>\n",
       "      <td>-0.339758</td>\n",
       "      <td>-0.078346</td>\n",
       "      <td>-0.194041</td>\n",
       "      <td>-0.392661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>-0.219189</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.145924</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_0024200.jpg</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.873723</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.264057</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.158138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.771429</td>\n",
       "      <td>-0.108309</td>\n",
       "      <td>0.728530</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401054</th>\n",
       "      <td>IP_1140263</td>\n",
       "      <td>ISIC_9999937</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_9999937.jpg</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.576642</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.042252</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>-0.104138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.245916</td>\n",
       "      <td>0.520086</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401055</th>\n",
       "      <td>IP_5678181</td>\n",
       "      <td>ISIC_9999951</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_9999951.jpg</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.845985</td>\n",
       "      <td>-0.113409</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.267848</td>\n",
       "      <td>0.112787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.092871</td>\n",
       "      <td>0.663540</td>\n",
       "      <td>0.371353</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401056</th>\n",
       "      <td>IP_0076153</td>\n",
       "      <td>ISIC_9999960</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_9999960.jpg</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.923358</td>\n",
       "      <td>-0.217799</td>\n",
       "      <td>-0.069685</td>\n",
       "      <td>0.111101</td>\n",
       "      <td>-0.117786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542857</td>\n",
       "      <td>0.096538</td>\n",
       "      <td>0.440455</td>\n",
       "      <td>-0.394544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401057</th>\n",
       "      <td>IP_5231513</td>\n",
       "      <td>ISIC_9999964</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_9999964.jpg</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.868613</td>\n",
       "      <td>-0.022207</td>\n",
       "      <td>-0.191141</td>\n",
       "      <td>0.059713</td>\n",
       "      <td>-0.091611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.007523</td>\n",
       "      <td>0.312739</td>\n",
       "      <td>-0.296878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401058</th>\n",
       "      <td>IP_6426047</td>\n",
       "      <td>ISIC_9999967</td>\n",
       "      <td>0</td>\n",
       "      <td>./2024/train-image/image/ISIC_9999967.jpg</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.832117</td>\n",
       "      <td>-0.239098</td>\n",
       "      <td>-0.110016</td>\n",
       "      <td>-0.193711</td>\n",
       "      <td>-0.387880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485714</td>\n",
       "      <td>-0.409367</td>\n",
       "      <td>-0.183142</td>\n",
       "      <td>0.307387</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401059 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id       isic_id  target  \\\n",
       "0       IP_1235828  ISIC_0015670       0   \n",
       "1       IP_8170065  ISIC_0015845       0   \n",
       "2       IP_6724798  ISIC_0015864       0   \n",
       "3       IP_4111386  ISIC_0015902       0   \n",
       "4       IP_8313778  ISIC_0024200       0   \n",
       "...            ...           ...     ...   \n",
       "401054  IP_1140263  ISIC_9999937       0   \n",
       "401055  IP_5678181  ISIC_9999951       0   \n",
       "401056  IP_0076153  ISIC_9999960       0   \n",
       "401057  IP_5231513  ISIC_9999964       0   \n",
       "401058  IP_6426047  ISIC_9999967       0   \n",
       "\n",
       "                                        file_path  age_approx  \\\n",
       "0       ./2024/train-image/image/ISIC_0015670.jpg       0.375   \n",
       "1       ./2024/train-image/image/ISIC_0015845.jpg       0.375   \n",
       "2       ./2024/train-image/image/ISIC_0015864.jpg       0.375   \n",
       "3       ./2024/train-image/image/ISIC_0015902.jpg       0.500   \n",
       "4       ./2024/train-image/image/ISIC_0024200.jpg       0.250   \n",
       "...                                           ...         ...   \n",
       "401054  ./2024/train-image/image/ISIC_9999937.jpg       0.625   \n",
       "401055  ./2024/train-image/image/ISIC_9999951.jpg       0.375   \n",
       "401056  ./2024/train-image/image/ISIC_9999960.jpg       0.500   \n",
       "401057  ./2024/train-image/image/ISIC_9999964.jpg      -0.375   \n",
       "401058  ./2024/train-image/image/ISIC_9999967.jpg       0.125   \n",
       "\n",
       "        clin_size_long_diam_mm  tbp_lv_A  tbp_lv_Aext  tbp_lv_B  tbp_lv_Bext  \\\n",
       "0                    -0.851095 -0.102881     0.099400  0.004887    -0.247862   \n",
       "1                    -0.992701  0.349720     0.494297 -0.016605    -0.217479   \n",
       "2                    -0.824818 -0.010870     0.136977  0.406357     0.239195   \n",
       "3                    -0.837956 -0.339758    -0.078346 -0.194041    -0.392661   \n",
       "4                    -0.873723  0.073970     0.264057 -0.011739    -0.158138   \n",
       "...                        ...       ...          ...       ...          ...   \n",
       "401054               -0.576642 -0.010929     0.042252  0.031807    -0.104138   \n",
       "401055               -0.845985 -0.113409     0.089201  0.267848     0.112787   \n",
       "401056               -0.923358 -0.217799    -0.069685  0.111101    -0.117786   \n",
       "401057               -0.868613 -0.022207    -0.191141  0.059713    -0.091611   \n",
       "401058               -0.832117 -0.239098    -0.110016 -0.193711    -0.387880   \n",
       "\n",
       "        ...  tbp_lv_symm_2axis_angle  tbp_lv_x  tbp_lv_y  tbp_lv_z  sex  \\\n",
       "0       ...                -0.028571 -0.286449  0.133118 -0.183826    1   \n",
       "1       ...                -0.371429  0.008264  0.787694  0.142046    1   \n",
       "2       ...                 0.200000  0.207932  0.717163  0.717002    1   \n",
       "3       ...                 0.485714 -0.219189  0.696873  0.145924    1   \n",
       "4       ...                -0.771429 -0.108309  0.728530  0.025096    1   \n",
       "...     ...                      ...       ...       ...       ...  ...   \n",
       "401054  ...                 0.142857  0.245916  0.520086  0.356273    1   \n",
       "401055  ...                -0.714286  0.092871  0.663540  0.371353    1   \n",
       "401056  ...                -0.542857  0.096538  0.440455 -0.394544    0   \n",
       "401057  ...                 0.600000 -0.007523  0.312739 -0.296878    0   \n",
       "401058  ...                -0.485714 -0.409367 -0.183142  0.307387    1   \n",
       "\n",
       "        anatom_site_general  tbp_tile_type  tbp_lv_location  \\\n",
       "0                         2              1               12   \n",
       "1                         1              1                0   \n",
       "2                         3              0               16   \n",
       "3                         0              0               19   \n",
       "4                         0              1               19   \n",
       "...                     ...            ...              ...   \n",
       "401054                    0              0               19   \n",
       "401055                    3              1               16   \n",
       "401056                    0              0               19   \n",
       "401057                    0              0               18   \n",
       "401058                    2              0                5   \n",
       "\n",
       "        tbp_lv_location_simple  attribution  \n",
       "0                            4            4  \n",
       "1                            0            4  \n",
       "2                            5            4  \n",
       "3                            6            0  \n",
       "4                            6            4  \n",
       "...                        ...          ...  \n",
       "401054                       6            1  \n",
       "401055                       5            4  \n",
       "401056                       6            3  \n",
       "401057                       6            5  \n",
       "401058                       2            2  \n",
       "\n",
       "[401059 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols   = [\n",
    "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
    "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
    "    'tbp_lv_A',                          # A inside  lesion.+\n",
    "    'tbp_lv_Aext',                       # A outside lesion.+\n",
    "    'tbp_lv_B',                          # B inside  lesion.+\n",
    "    'tbp_lv_Bext',                       # B outside lesion.+ \n",
    "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
    "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
    "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
    "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
    "    'tbp_lv_L',                          # L inside lesion.+\n",
    "    'tbp_lv_Lext',                       # L outside lesion.+\n",
    "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
    "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
    "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
    "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaLB',                    #\n",
    "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
    "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
    "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
    "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
    "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
    "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
    "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
    "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
    "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
    "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
    "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
    "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
    "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
    "]\n",
    "\n",
    "new_num_cols = [\n",
    "    'lesion_size_ratio',                 # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
    "    'lesion_shape_index',                # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
    "    'hue_contrast',                      # tbp_lv_H                - tbp_lv_Hext              abs\n",
    "    'luminance_contrast',                # tbp_lv_L                - tbp_lv_Lext              abs\n",
    "    'lesion_color_difference',           # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n",
    "    'border_complexity',                 # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
    "    'color_uniformity',                  # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
    "\n",
    "    'position_distance_3d',              # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
    "    'perimeter_to_area_ratio',           # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
    "    'area_to_perimeter_ratio',           # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "    'lesion_visibility_score',           # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
    "    'symmetry_border_consistency',       # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
    "    'consistency_symmetry_border',       # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "\n",
    "    'color_consistency',                 # tbp_lv_stdL             / tbp_lv_Lext\n",
    "    'consistency_color',                 # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "    'size_age_interaction',              # clin_size_long_diam_mm  * age_approx\n",
    "    'hue_color_std_interaction',         # tbp_lv_H                * tbp_lv_color_std_mean\n",
    "    'lesion_severity_index',             # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
    "    'shape_complexity_index',            # border_complexity       + lesion_shape_index\n",
    "    'color_contrast_index',              # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
    "\n",
    "    'log_lesion_area',                   # tbp_lv_areaMM2          + 1  np.log\n",
    "    'normalized_lesion_size',            # clin_size_long_diam_mm  / age_approx\n",
    "    'mean_hue_difference',               # tbp_lv_H                + tbp_lv_Hext    / 2\n",
    "    'std_dev_contrast',                  # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
    "    'color_shape_composite_index',       # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
    "    'lesion_orientation_3d',             # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
    "    'overall_color_difference',          # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
    "\n",
    "    'symmetry_perimeter_interaction',    # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
    "    'comprehensive_lesion_index',        # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
    "    'color_variance_ratio',              # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
    "    'border_color_interaction',          # tbp_lv_norm_border      * tbp_lv_norm_color\n",
    "    'border_color_interaction_2',\n",
    "    'size_color_contrast_ratio',         # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
    "    'age_normalized_nevi_confidence',    # tbp_lv_nevi_confidence  / age_approx\n",
    "    #'age_normalized_nevi_confdnce_2',\n",
    "    'color_asymmetry_index',             # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
    "\n",
    "    'volume_approximation_3d',           # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
    "    'color_range',                       # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
    "    'shape_color_consistency',           # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
    "    'border_length_ratio',               # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
    "    'age_size_symmetry_index',           # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
    "    'index_age_size_symmetry',           # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "    \n",
    "]\n",
    "\n",
    "cat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\n",
    "\n",
    "label_encoders=  {}\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)) #StandardScaler()\n",
    "label_encoder = LabelEncoder()\n",
    "for column in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "# 进行编码\n",
    "\n",
    "df =  df_2024[['patient_id', 'isic_id', 'target', 'file_path']+num_cols+cat_cols]\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 2, 21, 8, 7]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dim = [df[i].max()+1 for i in cat_cols]\n",
    "cat_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['target']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['target']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.020234,
     "end_time": "2024-06-29T23:17:58.473737",
     "exception": false,
     "start_time": "2024-06-29T23:17:58.453503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100264"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['T_max'] = df.shape[0] * (CONFIG[\"n_fold\"]-1) * CONFIG['epochs'] // CONFIG['train_batch_size'] // CONFIG[\"n_fold\"]\n",
    "CONFIG['T_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols] = df[num_cols].fillna(-1)\n",
    "inputs = df[num_cols].values\n",
    "if np.isnan(inputs).any() or np.isinf(inputs).any():\n",
    "    print(\"Input data contains NaN or Inf values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.466594,
     "end_time": "2024-06-29T23:17:58.975943",
     "exception": false,
     "start_time": "2024-06-29T23:17:58.509349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(sgkf.split(df, df.target,df.patient_id)):\n",
    "      df.loc[val_ , \"kfold\"] = int(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 0.027666,
     "end_time": "2024-06-29T23:17:59.039604",
     "exception": false,
     "start_time": "2024-06-29T23:17:59.011938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_valid_augment(image_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    # transform = A.Compose([\n",
    "    #     A.Resize(image_size, image_size),\n",
    "    #     A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_train_augment(image_size):\n",
    "    augment_policy = 'autoaugment'  # 可以替换为其他策略，如 'autoaugment', 'trivialaugment'\n",
    "\n",
    "    # 创建数据增强变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        #transforms.RandomCrop((224, 224)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #transforms.Resize(image_size),\n",
    "        #auto_augment_transform(config_str = 'original' ,hparams = {'translate_const': 100,}),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "     ])\n",
    "    # transform = A.Compose([\n",
    "    #     A.Transpose(p=0.5),\n",
    "    #     A.VerticalFlip(p=0.5),\n",
    "    #     A.HorizontalFlip(p=0.5),\n",
    "    #     A.RandomBrightnessContrast(p=0.75),\n",
    "    #     A.OneOf([\n",
    "    #         A.MotionBlur(blur_limit=5),\n",
    "    #         A.MedianBlur(blur_limit=5),\n",
    "    #         A.GaussianBlur(blur_limit=5),\n",
    "    #         A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "    #     ], p=0.7),\n",
    "\n",
    "    #     A.OneOf([\n",
    "    #         A.OpticalDistortion(distort_limit=1.0),\n",
    "    #         A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    #         A.ElasticTransform(alpha=3),\n",
    "    #     ], p=0.7),\n",
    "\n",
    "    #     A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "    #     A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "    #     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "    #     A.Resize(image_size, image_size),\n",
    "    #     A.CoarseDropout(max_height=int(image_size * 0.375), max_width=int(image_size * 0.375), p=0.7),    \n",
    "    #     A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, df, augment):\n",
    "        self.df = df\n",
    "        self.targets = df['target'].tolist()\n",
    "        self.augment = augment\n",
    "        self.length = len(self.df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.df.iloc[index]\n",
    "        img_path = d.file_path\n",
    "        m = Image.open(img_path)\n",
    "        r = self.augment(m)\n",
    "        \n",
    "\n",
    "        r = {\n",
    "            #'index': index,\n",
    "            'image': r,\n",
    "            'target':self.targets[index]\n",
    "        }\n",
    "        return r\n",
    "class MultiModSkinDataset(Dataset):\n",
    "    def __init__(self, df, augment):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.targets = df['target'].tolist()\n",
    "        self.file_path = df['file_path'].tolist()\n",
    "        self.augment = augment\n",
    "        self.length = len(self.df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path = self.file_path[index]\n",
    "        # false_color = cv2.imread(img_path)\n",
    "        # false_color = cv2.cvtColor(false_color, cv2.COLOR_BGR2RGB)\n",
    "        # transformed = self.augment(image=false_color)\n",
    "        # transformed_image = transformed['image']\n",
    "        # r = torch.from_numpy(transformed_image).permute(2, 0, 1)\n",
    "        m = Image.open(img_path)\n",
    "        r = self.augment(m)\n",
    "        num_feature =  np.array(self.df.loc[index, num_cols].values, dtype=np.float32)\n",
    "        cat_feature = np.array(self.df.loc[index, cat_cols].values, dtype=np.int64)\n",
    "        r = {\n",
    "            #'index': index,\n",
    "            'image': r,\n",
    "            'target':self.targets[index],\n",
    "            'num_cols': num_feature,\n",
    "            'cat_cols': cat_feature,\n",
    "        }\n",
    "        return r\n",
    "\n",
    "def null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        d[k] = [b[k] for b in batch]\n",
    "    d['image'] = torch.stack(d['image']).float()\n",
    "    d['target'] = torch.as_tensor(d['target'], dtype=torch.long)#.float()\n",
    "\n",
    "    return d\n",
    "\n",
    "def multi_mod_null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        d[k] = [b[k] for b in batch]\n",
    "    #print(d['num_cols'])\n",
    "    #print(d['cat_cols'])\n",
    "    d['image'] = torch.stack(d['image']).float()\n",
    "    d['num_cols'] = torch.stack([torch.as_tensor(i) for i in d['num_cols']])\n",
    "    d['cat_cols'] = torch.stack([torch.as_tensor(i) for i in d['cat_cols']]).long()\n",
    "    d['target'] = torch.as_tensor(d['target'], dtype=torch.long)#.float()\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011484,
     "end_time": "2024-06-29T23:17:59.062869",
     "exception": false,
     "start_time": "2024-06-29T23:17:59.051385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_rgb2hsv(rgb: torch.Tensor) -> torch.Tensor:\n",
    "    cmax, cmax_idx = torch.max(rgb, dim=1, keepdim=True)\n",
    "    cmin = torch.min(rgb, dim=1, keepdim=True)[0]\n",
    "    delta = cmax - cmin\n",
    "    hsv_h = torch.empty_like(rgb[:, 0:1, :, :])\n",
    "    cmax_idx[delta == 0] = 3\n",
    "    hsv_h[cmax_idx == 0] = (((rgb[:, 1:2] - rgb[:, 2:3]) / delta) % 6)[cmax_idx == 0]\n",
    "    hsv_h[cmax_idx == 1] = (((rgb[:, 2:3] - rgb[:, 0:1]) / delta) + 2)[cmax_idx == 1]\n",
    "    hsv_h[cmax_idx == 2] = (((rgb[:, 0:1] - rgb[:, 1:2]) / delta) + 4)[cmax_idx == 2]\n",
    "    hsv_h[cmax_idx == 3] = 0.\n",
    "    hsv_h /= 6.\n",
    "    hsv_s = torch.where(cmax == 0, torch.tensor(0.).type_as(rgb), delta / cmax)\n",
    "    hsv_v = cmax\n",
    "    return torch.cat([hsv_h, hsv_s, hsv_v], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(Net, self).__init__()\n",
    "        self.output_type = ['infer', 'loss']\n",
    "        arch = CONFIG['model_name']\n",
    "\n",
    "        self.model_name = CONFIG['model_name']\n",
    "\n",
    "        self.model = timm.create_model(model_name=arch, pretrained=pretrained, in_chans=6,  num_classes=0, global_pool='')\n",
    "        #print(f'Feature channels: {self.model.feature_info}')\n",
    "        in_features =  self.model.num_features\n",
    "        self.target=nn.Linear(in_features, 2)\n",
    "\n",
    "        self.dropout = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for i in range(5)\n",
    "        ]) #droupout augmentation\n",
    "\n",
    "       \n",
    "    def forward(self, batch):\n",
    "        image = batch['image']\n",
    "        batch_size = len(image)\n",
    "        image = image.float()/255\n",
    "        image = torch.cat([image, F_rgb2hsv(image)],1)\n",
    "        # image = (image-self.mean)/self.std\n",
    "        x = self.model(image)\n",
    "        pool = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "\n",
    "        if self.training:\n",
    "            logit=0\n",
    "            for i in range(len(self.dropout)):\n",
    "                logit += self.target(self.dropout[i](pool))\n",
    "            logit = logit/len(self.dropout)\n",
    "        else:\n",
    "            logit = self.target(pool)\n",
    "        output = {}\n",
    "        target = batch['target']\n",
    "        \n",
    "        #output['loss'] = self.loss_fn(logit, target)\n",
    "        pred_prob = logit.softmax(dim=-1)[:, 1]\n",
    "        #print(pred_prob)\n",
    "        output['logit'] = logit\n",
    "        output['pred'] = pred_prob\n",
    "        output['pool'] = pool\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab_transformer_pytorch import TabTransformer\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class Swish_Module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "\n",
    "class MultiModNet(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(MultiModNet, self).__init__()\n",
    "        self.output_type = ['infer', 'loss']\n",
    "        arch = CONFIG['model_name']\n",
    "\n",
    "        self.model_name = CONFIG['model_name']\n",
    "\n",
    "        self.model = timm.create_model(model_name=arch, pretrained=pretrained, in_chans=6,  num_classes=0, global_pool='')\n",
    "        self.meta = nn.Sequential(\n",
    "                nn.Linear( len(cat_cols)+len(num_cols), 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                Swish_Module(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                Swish_Module(),\n",
    "            )\n",
    "        self.mlp = nn.Linear(self.model.num_features + 128, 2)\n",
    "    def forward(self, batch):\n",
    "        image = batch['image']\n",
    "        num_cols = batch['num_cols']\n",
    "        cat_cols = batch['cat_cols']\n",
    "        #print(cat_cols)\n",
    "        #print(num_cols)\n",
    "        batch_size = len(image)\n",
    "        image = image.float()/255\n",
    "        image = torch.cat([image, F_rgb2hsv(image)],1)\n",
    "        # image = (image-self.mean)/self.std\n",
    "        x = self.model(image)\n",
    "        pool = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        \n",
    "        meta_feature = torch.cat([cat_cols, num_cols], dim=1)\n",
    "        meta_feature = self.meta(meta_feature)\n",
    "\n",
    "        logit = torch.cat((meta_feature, pool), dim=1)\n",
    "        logit = self.mlp(logit)\n",
    "        output = {}\n",
    "        target = batch['target']\n",
    "        \n",
    "        #output['loss'] = self.loss_fn(logit, target)\n",
    "        pred_prob = logit.softmax(dim=-1)[:, 1]\n",
    "        #print(pred_prob)\n",
    "        output['logit'] = logit\n",
    "        output['pred'] = pred_prob\n",
    "        output['pool'] = pool\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab_transformer_pytorch import TabTransformer\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class Swish_Module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "\n",
    "class MultiModTabNet(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(MultiModTabNet, self).__init__()\n",
    "        self.output_type = ['infer', 'loss']\n",
    "        arch = CONFIG['model_name']\n",
    "\n",
    "        self.model_name = CONFIG['model_name']\n",
    "\n",
    "        self.model = timm.create_model(model_name=arch, pretrained=pretrained, in_chans=6,  num_classes=0, global_pool='')\n",
    "        self.tab_transformer = TabTransformer(\n",
    "                                categories = cat_dim,      # tuple containing the number of unique values within each category\n",
    "                                num_continuous = self.model.num_features,# + len(num_cols),                # number of continuous values\n",
    "                                dim = 32,                           # dimension, paper set at 32\n",
    "                                dim_out = 2,                        # binary prediction, but could be anything\n",
    "                                depth = 6,                          # depth, paper recommended 6\n",
    "                                heads = 8,                          # heads, paper recommends 8\n",
    "                                attn_dropout = 0.1,                 # post-attention dropout\n",
    "                                ff_dropout = 0.1,                   # feed forward dropout\n",
    "                                mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n",
    "                                mlp_act = nn.Tanh(),                # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n",
    "                                continuous_mean_std = None # (optional) - normalize the continuous values before layer norm\n",
    "                            )\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        image = batch['image']\n",
    "        num_cols = batch['num_cols']\n",
    "        cat_cols = batch['cat_cols']\n",
    "        #print(cat_cols)\n",
    "        #print(num_cols)\n",
    "        batch_size = len(image)\n",
    "        image = image.float()/255\n",
    "        image = torch.cat([image, F_rgb2hsv(image)],1)\n",
    "        # image = (image-self.mean)/self.std\n",
    "        x = self.model(image)\n",
    "        pool = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        \n",
    "        num_feature = pool#torch.cat([pool, num_cols], dim=1)\n",
    "        \n",
    "\n",
    "        logit =self.tab_transformer(cat_cols, num_feature)\n",
    "        \n",
    "        output = {}\n",
    "        target = batch['target']\n",
    "        \n",
    "        #output['loss'] = self.loss_fn(logit, target)\n",
    "        pred_prob = logit.softmax(dim=-1)[:, 1]\n",
    "        #print(pred_prob)\n",
    "        output['logit'] = logit\n",
    "        output['pred'] = pred_prob\n",
    "        output['pool'] = pool\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011944,
     "end_time": "2024-06-29T23:18:00.456944",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(gts, preds, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(gts)-1)\n",
    "    v_pred = np.array([1.0 - x for x in preds])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "papermill": {
     "duration": 0.024329,
     "end_time": "2024-06-29T23:18:00.493233",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.468904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, model_ema, optimizer, scheduler, dataloader, device, epoch, mixup_fn=None):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc  = 0.0\n",
    "    if CONFIG['using_mix_up']:\n",
    "        loss_fn = SoftTargetCrossEntropy().cuda()\n",
    "    else:\n",
    "        loss_fn = F.cross_entropy\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for step, data in bar:\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "        \n",
    "        batch_size = data['image'].size(0)\n",
    "        if CONFIG['using_mix_up']:\n",
    "            image = data['image']\n",
    "            ori_target = data['target']\n",
    "            \n",
    "            image, target = mixup_fn(image, ori_target)\n",
    "            data['image'] = image\n",
    "            data['target'] = target\n",
    "\n",
    "        outputs = model(data)\n",
    "        if CONFIG['using_mix_up']:\n",
    "            loss = loss_fn(outputs['logit'], data['target'])\n",
    "            targets = ori_target\n",
    "        else:\n",
    "            loss = loss_fn(outputs['logit'], data['target'].long())\n",
    "            targets = data['target'].long()\n",
    "        pred = outputs['pred']\n",
    "        #print(outputs['logit'])\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if torch.isnan(param).any() or torch.isinf(param).any():\n",
    "        #         print(f\"Parameter {name} contains NaN or Inf values!\")\n",
    "\n",
    "        gts.append(targets.squeeze().cpu().numpy().reshape(-1))\n",
    "        preds.append(pred.squeeze().detach().cpu().numpy().reshape(-1))\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            wandb.log({\"epoch\": epoch, \"loss\": loss.item(), })\n",
    "            grad = torch.nn.utils.clip_grad_norm_(model.parameters(), 500)\n",
    "            #print(grad.item())\n",
    "            #print(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            #model_ema.update(model)\n",
    "        #auroc = comp_score(targets.squeeze().cpu().numpy(), preds.squeeze().detach().cpu().numpy())\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        #running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        #epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Grad = grad.item())\n",
    "    gc.collect()\n",
    "    gts = np.concatenate(gts)\n",
    "    preds = np.concatenate(preds)\n",
    "    epoch_auroc = comp_score(gts, preds)\n",
    "    return epoch_loss, epoch_auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011634,
     "end_time": "2024-06-29T23:18:00.516892",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.505258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 0.02315,
     "end_time": "2024-06-29T23:18:00.551972",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.528822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "    preds = []\n",
    "    gts = []\n",
    "    pools = []\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "        \n",
    "        batch_size = data['image'].size(0)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        loss = F.cross_entropy(outputs['logit'],  data['target'].long())\n",
    "        pred = outputs['pred']\n",
    "        targets = data['target']\n",
    "        pool = outputs['pool']\n",
    "        gts.append(targets.squeeze().cpu().numpy().reshape(-1))\n",
    "        preds.append(pred.squeeze().detach().cpu().numpy().reshape(-1))\n",
    "        pools.append(pool.squeeze().detach().cpu().numpy())\n",
    "        #auroc = comp_score(targets.squeeze().cpu().numpy(), preds.squeeze().detach().cpu().numpy())\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        #running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        #epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss)   \n",
    "    \n",
    "    gc.collect()\n",
    "    gts = np.concatenate(gts)\n",
    "    preds = np.concatenate(preds)\n",
    "    epoch_auroc = comp_score(gts, preds)\n",
    "    pools = np.vstack(pools)\n",
    "    return epoch_loss, epoch_auroc, pools, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011798,
     "end_time": "2024-06-29T23:18:00.575765",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.563967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 0.026227,
     "end_time": "2024-06-29T23:18:00.614057",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.58783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auroc = -np.inf\n",
    "    history = defaultdict(list)\n",
    "    mixup_args = {\n",
    "                'mixup_alpha': 0,\n",
    "                'cutmix_alpha': 1,\n",
    "                'cutmix_minmax': None,\n",
    "                'prob': 1.0,\n",
    "                'switch_prob': 0,\n",
    "                'mode': 'elem',\n",
    "                'label_smoothing': 0,\n",
    "                'num_classes': 2}\n",
    "    mixup_fn = Mixup(**mixup_args)\n",
    "    if not CONFIG['using_mix_up']:\n",
    "        mixup_fn = None\n",
    "    model_ema = ModelEmaV2(model, decay=0.9999)\n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_loader, valid_loader = prepare_loaders_mulit_mod(df, fold=CONFIG[\"fold\"])\n",
    "        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, model_ema, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch, mixup_fn=mixup_fn)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_auroc, val_features, val_preds = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train AUROC'].append(train_epoch_auroc)\n",
    "        history['Valid AUROC'].append(val_epoch_auroc)\n",
    "        #history['lr'].append( scheduler.get_lr()[0] )\n",
    "        wandb.log({\"val_loss\": val_epoch_loss, \"val_p_auc\": val_epoch_auroc})\n",
    "        # deep copy the model\n",
    "        if best_epoch_auroc <= val_epoch_auroc:\n",
    "            print(f\"Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n",
    "            best_epoch_auroc = val_epoch_auroc\n",
    "            PATH = f\"best_{best_epoch_auroc}.bin\"\n",
    "            output_dir = CONFIG['output_dir']\n",
    "            torch.save(model.state_dict(), f'./{output_dir}/fold_{fold}_{PATH}')\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "            best_val_features = val_features\n",
    "            best_val_preds = val_preds\n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history, best_val_features, best_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "papermill": {
     "duration": 0.020426,
     "end_time": "2024-06-29T23:18:00.646386",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.62596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders_mulit_mod(df, fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    # df_train_pos = df_train[df_train['target']==1]\n",
    "    # df_train_neg = df_train[df_train['target']==0].smaple(n=CONFIG['undersample_rate']*len(df_train_pos), random_state=64)\n",
    "    # df_train = pd.concat([df_train_pos, df_train_neg]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    train_dataset = MultiModSkinDataset(df_train, augment=make_train_augment(image_size=CONFIG['img_size']))\n",
    "    valid_dataset = MultiModSkinDataset(df_valid, augment=make_valid_augment(image_size=CONFIG['img_size']))\n",
    "    sampler = DualSampler(train_dataset, batch_size=CONFIG['train_batch_size'], sampling_rate=0.05)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=1, shuffle=True, pin_memory=True, collate_fn=multi_mod_null_collate,\n",
    "                              #sampler=sampler\n",
    "                             )\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=1, shuffle=False, pin_memory=True, collate_fn=multi_mod_null_collate,)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 4090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10027 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     10\u001b[0m                        weight_decay\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m fetch_scheduler(optimizer)\n\u001b[0;32m---> 12\u001b[0m model, history, best_val_features, best_val_preds \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m val_df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mkfold \u001b[38;5;241m==\u001b[39m fold]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misic_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     19\u001b[0m val_features \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mDataFrame(best_val_features, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_features_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(best_val_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs, fold)\u001b[0m\n\u001b[1;32m     25\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     26\u001b[0m train_loader, valid_loader \u001b[38;5;241m=\u001b[39m prepare_loaders_mulit_mod(df, fold\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m train_epoch_loss, train_epoch_auroc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixup_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m val_epoch_loss, val_epoch_auroc, val_features, val_preds \u001b[38;5;241m=\u001b[39m valid_one_epoch(model, valid_loader, device\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     32\u001b[0m                                  epoch\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[1;32m     34\u001b[0m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n",
      "Cell \u001b[0;32mIn[23], line 27\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, model_ema, optimizer, scheduler, dataloader, device, epoch, mixup_fn)\u001b[0m\n\u001b[1;32m     24\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m     25\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musing_mix_up\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     29\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogit\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 51\u001b[0m, in \u001b[0;36mMultiModNet.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     49\u001b[0m image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([image, F_rgb2hsv(image)],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# image = (image-self.mean)/self.std\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m pool \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch_size,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m meta_feature \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([cat_cols, num_cols], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/timm/models/efficientnet.py:179\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 179\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/timm/models/efficientnet.py:167\u001b[0m, in \u001b[0;36mEfficientNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, x, flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_head(x)\n\u001b[1;32m    169\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/timm/models/_efficientnet_blocks.py:181\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_pw(x)\n\u001b[0;32m--> 181\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_dw(x)\n\u001b[1;32m    183\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/timm/layers/norm_act.py:118\u001b[0m, in \u001b[0;36mBatchNormAct2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(x)\n\u001b[1;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/nn/functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "oof = []\n",
    "for i in range(1):\n",
    "    CONFIG[\"fold\"] = i\n",
    "    \n",
    "    model = MultiModNet(False)\n",
    "    pre_weight = torch.load(CONFIG['checkpoint_path'])\n",
    "    #model.load_state_dict(pre_weight, strict=False)\n",
    "    model.cuda()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                           weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history, best_val_features, best_val_preds = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=CONFIG[\"fold\"]\n",
    "                                 )\n",
    "    \n",
    "    val_df = df[df.kfold == fold].reset_index(drop=True)[['patient_id', 'isic_id']]\n",
    "    val_features =  pd.DataFrame(best_val_features, columns=[f'cnn_features_{i}' for i in range(best_val_features.shape[1])])\n",
    "    val_df = pd.concat([val_df, val_features], axis=1)\n",
    "    val_df['preds'] = best_val_preds\n",
    "    oof.append(val_df)\n",
    "oof = pd.concat(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "papermill": {
     "duration": 0.033503,
     "end_time": "2024-06-29T23:18:00.747996",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.714493",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 4090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [09:54<00:00,  2.11it/s, Epoch=1, Grad=0.0194, Train_Loss=0.00918] \n",
      "100%|██████████| 314/314 [02:28<00:00,  2.12it/s, Epoch=1, Valid_Loss=0.00669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (-inf ---> 0.13087291449160318)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [10:01<00:00,  2.08it/s, Epoch=2, Grad=0.0341, Train_Loss=0.00662] \n",
      "100%|██████████| 314/314 [02:31<00:00,  2.08it/s, Epoch=2, Valid_Loss=0.00593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.13087291449160318 ---> 0.15082315044378586)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [10:05<00:00,  2.07it/s, Epoch=3, Grad=0.0358, Train_Loss=0.00621] \n",
      "100%|██████████| 314/314 [02:30<00:00,  2.09it/s, Epoch=3, Valid_Loss=0.00607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [09:50<00:00,  2.12it/s, Epoch=4, Grad=0.0325, Train_Loss=0.00597] \n",
      "100%|██████████| 314/314 [02:43<00:00,  1.92it/s, Epoch=4, Valid_Loss=0.00623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.15082315044378586 ---> 0.15629058340267063)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [10:01<00:00,  2.08it/s, Epoch=5, Grad=0.0139, Train_Loss=0.00566] \n",
      "100%|██████████| 314/314 [02:30<00:00,  2.09it/s, Epoch=5, Valid_Loss=0.00555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.15629058340267063 ---> 0.16106171513364456)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [10:05<00:00,  2.07it/s, Epoch=6, Grad=0.00792, Train_Loss=0.00543]\n",
      "100%|██████████| 314/314 [02:29<00:00,  2.11it/s, Epoch=6, Valid_Loss=0.0055] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [10:06<00:00,  2.07it/s, Epoch=7, Grad=0.00456, Train_Loss=0.00518]\n",
      "100%|██████████| 314/314 [02:31<00:00,  2.08it/s, Epoch=7, Valid_Loss=0.0054] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.16106171513364456 ---> 0.16504186656182065)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [10:06<00:00,  2.07it/s, Epoch=8, Grad=0.0147, Train_Loss=0.00499] \n",
      "100%|██████████| 314/314 [02:29<00:00,  2.09it/s, Epoch=8, Valid_Loss=0.00533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.16504186656182065 ---> 0.16700409930249946)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 197/1254 [01:36<08:47,  2.00it/s, Epoch=9, Grad=0.0173, Train_Loss=0.00407] ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      " 16%|█▌        | 198/1254 [02:54<15:31,  1.13it/s, Epoch=9, Grad=0.00909, Train_Loss=0.00406]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 15903, 15904) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 15904) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     10\u001b[0m                        weight_decay\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m fetch_scheduler(optimizer)\n\u001b[0;32m---> 12\u001b[0m model, history, best_val_features, best_val_preds \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m val_df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mkfold \u001b[38;5;241m==\u001b[39m fold]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misic_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     19\u001b[0m val_features \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mDataFrame(best_val_features, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_features_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(best_val_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs, fold)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m): \n\u001b[1;32m     25\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 26\u001b[0m     train_epoch_loss, train_epoch_auroc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixup_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     val_epoch_loss, val_epoch_auroc, val_features, val_preds \u001b[38;5;241m=\u001b[39m valid_one_epoch(model, valid_loader, device\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     31\u001b[0m                                      epoch\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[1;32m     33\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, model_ema, optimizer, scheduler, dataloader, device, epoch, mixup_fn)\u001b[0m\n\u001b[1;32m     12\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m gts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m bar:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     16\u001b[0m         data[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 15903, 15904) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "oof = []\n",
    "for i in range(5):\n",
    "    CONFIG[\"fold\"] = i\n",
    "    \n",
    "    model = MultiModNet(False)\n",
    "    pre_weight = torch.load(CONFIG['checkpoint_path'])\n",
    "    model.load_state_dict(pre_weight, strict=False)\n",
    "    model.cuda()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                           weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history, best_val_features, best_val_preds = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=CONFIG[\"fold\"]\n",
    "                                 )\n",
    "    \n",
    "    val_df = df[df.kfold == fold].reset_index(drop=True)[['patient_id', 'isic_id']]\n",
    "    val_features =  pd.DataFrame(best_val_features, columns=[f'cnn_features_{i}' for i in range(best_val_features.shape[1])])\n",
    "    val_df = pd.concat([val_df, val_features], axis=1)\n",
    "    val_df['preds'] = best_val_preds\n",
    "    oof.append(val_df)\n",
    "oof = pd.concat(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgkf\n",
    "# baseline fold0  0.1363120993115752\n",
    "# + mix-up fold0 0.13397867014309467 \n",
    "# + pretrained fold0 0.14820244272661473\n",
    "# + pretrained + autoaug fold0 0.144\n",
    "# + pretrained + ema fold0 0.09\n",
    "# + pretrained + meta data fold0  0.16700409930249946\n",
    "# meta data fold0  0.162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = []\n",
    "for i in range(5):\n",
    "    gts.append(df[df.kfold == i]['target'])\n",
    "gts = np.concatenate(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_score(gts, oof['preds'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.012164,
     "end_time": "2024-06-29T23:18:00.772504",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.76034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof.to_csv('./'+CONFIG['output_dir']+'/oof.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.408452,
     "end_time": "2024-06-29T23:30:27.325321",
     "exception": false,
     "start_time": "2024-06-29T23:30:26.916869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = pd.DataFrame.from_dict(history)\n",
    "history.to_csv(\"history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.390665,
     "end_time": "2024-06-29T23:30:28.107797",
     "exception": false,
     "start_time": "2024-06-29T23:30:27.717132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Logs</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.673512,
     "end_time": "2024-06-29T23:30:29.236485",
     "exception": false,
     "start_time": "2024-06-29T23:30:28.562973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot( range(history.shape[0]), history[\"Train Loss\"].values, label=\"Train Loss\")\n",
    "plt.plot( range(history.shape[0]), history[\"Valid Loss\"].values, label=\"Valid Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.648584,
     "end_time": "2024-06-29T23:30:30.277915",
     "exception": false,
     "start_time": "2024-06-29T23:30:29.629331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot( range(history.shape[0]), history[\"Train AUROC\"].values, label=\"Train AUROC\")\n",
    "plt.plot( range(history.shape[0]), history[\"Valid AUROC\"].values, label=\"Valid AUROC\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.617692,
     "end_time": "2024-06-29T23:30:31.290602",
     "exception": false,
     "start_time": "2024-06-29T23:30:30.67291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot( range(history.shape[0]), history[\"lr\"].values, label=\"lr\")\n",
    "# plt.xlabel(\"epochs\")\n",
    "# plt.ylabel(\"lr\")\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8940774,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5295517,
     "sourceId": 8805063,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5295538,
     "sourceId": 8805089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5295507,
     "sourceId": 8805188,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 2656,
     "sourceId": 3729,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 793.680734,
   "end_time": "2024-06-29T23:30:34.642937",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-29T23:17:20.962203",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "14f33eda98294bf7ab2c201ef8c071b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_efc119d2e1e0456fa0a6593c16a85dc2",
       "placeholder": "​",
       "style": "IPY_MODEL_f4be4b7893f14d71a8658ad521e9d4e9",
       "value": " 21.4M/21.4M [00:00&lt;00:00, 41.1MB/s]"
      }
     },
     "18bdb1a4a13e4aee9cc51601b980aca0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "244eb860d230481c85c8db4fd77fb99a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_47503710d50a4aaba66bd273e31797b0",
        "IPY_MODEL_938dc29705ca4174ab708b0e84ac456c",
        "IPY_MODEL_14f33eda98294bf7ab2c201ef8c071b0"
       ],
       "layout": "IPY_MODEL_18bdb1a4a13e4aee9cc51601b980aca0"
      }
     },
     "256368e0b8da40ffaab43806b6e7bdfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "47503710d50a4aaba66bd273e31797b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a1c7099741224d6d95e8f291dac107aa",
       "placeholder": "​",
       "style": "IPY_MODEL_e70b5a1f96bf4ddf9ac9271b3aa6ad1a",
       "value": "model.safetensors: 100%"
      }
     },
     "938dc29705ca4174ab708b0e84ac456c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c198e83f65a043f6b6886c6984bf6303",
       "max": 21355344,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_256368e0b8da40ffaab43806b6e7bdfc",
       "value": 21355344
      }
     },
     "a1c7099741224d6d95e8f291dac107aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c198e83f65a043f6b6886c6984bf6303": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e70b5a1f96bf4ddf9ac9271b3aa6ad1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "efc119d2e1e0456fa0a6593c16a85dc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4be4b7893f14d71a8658ad521e9d4e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
