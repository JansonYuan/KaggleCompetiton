{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"5\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 9.086974,
     "end_time": "2024-06-29T23:17:46.466572",
     "exception": false,
     "start_time": "2024-06-29T23:17:37.379598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold \n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "from glob import glob\n",
    "# Albumentations for augmentations\n",
    "#import albumentations as A\n",
    "#from albumentations.pytorch import ToTensorV2\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "# For colored terminal text\n",
    "from libauc.sampler import DualSampler  # data resampling (for binary class)\n",
    "from torchvision import datasets, transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.07116,
     "end_time": "2024-06-29T23:17:46.571192",
     "exception": false,
     "start_time": "2024-06-29T23:17:46.500032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 10,\n",
    "    \"img_size\": 384,\n",
    "    \"model_name\": \"resnet18\",\n",
    "    \"checkpoint_path\" : \"./resnet18_pretrained/resnet18.pth\",\n",
    "    \"train_batch_size\": 64,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 0,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 20,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'output_dir': 'resnet18_pretrained'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model URL: https://github.com/huggingface/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet18_a1_0-d63eafa0.pth\n"
     ]
    }
   ],
   "source": [
    "url = timm.models.get_pretrained_cfg('resnet18').url\n",
    "print(f\"Pretrained model URL: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010587,
     "end_time": "2024-06-29T23:17:46.59285",
     "exception": false,
     "start_time": "2024-06-29T23:17:46.582263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.021715,
     "end_time": "2024-06-29T23:17:46.625274",
     "exception": false,
     "start_time": "2024-06-29T23:17:46.603559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 7.631613,
     "end_time": "2024-06-29T23:17:58.409773",
     "exception": false,
     "start_time": "2024-06-29T23:17:50.77816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2024 = pd.read_csv(f\"./2024/train-metadata.csv\")\n",
    "df_2024['file_path'] = df_2024['isic_id'].apply(lambda x:f'./2024/train-image/image/{x}.jpg')\n",
    "df_2024 = df_2024[['patient_id', 'isic_id', 'target', 'file_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.read_csv(\"./2020/train-metadata.csv\")\n",
    "df_2020['file_path'] = df_2020['isic_id'].apply(lambda x:f'./2020/train-image/image/{x}.jpg')\n",
    "df_2020 = df_2020[['patient_id', 'isic_id', 'target', 'file_path']]\n",
    "\n",
    "df_2019 = pd.read_csv(\"./2019/train-metadata.csv\")\n",
    "df_2019['file_path'] = df_2019['isic_id'].apply(lambda x:f'./2019/train-image/image/{x}.jpg')\n",
    "df_2019 = df_2019[['patient_id', 'isic_id', 'target', 'file_path']]\n",
    "\n",
    "df_2018 = pd.read_csv(\"./2018/train-metadata.csv\")\n",
    "images_path = glob('./2018/train-image/image/*.jpg')\n",
    "df_2018['file_path'] = df_2018['isic_id'].apply(lambda x:f'./2018/train-image/image/{x}.jpg')\n",
    "df_2018 = df_2018[['patient_id', 'isic_id', 'target', 'file_path']]\n",
    "df_2018 = df_2018[df_2018['file_path'].isin(images_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2020, df_2019, df_2018]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['target']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60185"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['target']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.020234,
     "end_time": "2024-06-29T23:17:58.473737",
     "exception": false,
     "start_time": "2024-06-29T23:17:58.453503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9789"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['T_max'] = df.shape[0] * (CONFIG[\"n_fold\"]-1) * CONFIG['epochs'] // CONFIG['train_batch_size'] // CONFIG[\"n_fold\"]\n",
    "CONFIG['T_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.466594,
     "end_time": "2024-06-29T23:17:58.975943",
     "exception": false,
     "start_time": "2024-06-29T23:17:58.509349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(sgkf.split(df, df.target,df.patient_id)):\n",
    "      df.loc[val_ , \"kfold\"] = int(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.027666,
     "end_time": "2024-06-29T23:17:59.039604",
     "exception": false,
     "start_time": "2024-06-29T23:17:59.011938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_valid_augment(image_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_train_augment(image_size):\n",
    "    augment_policy = 'autoaugment'  # 可以替换为其他策略，如 'autoaugment', 'trivialaugment'\n",
    "\n",
    "    # 创建数据增强变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomCrop((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, df, augment):\n",
    "        self.df = df\n",
    "        self.targets = df['target'].tolist()\n",
    "        self.augment = augment\n",
    "        self.length = len(self.df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.df.iloc[index]\n",
    "        img_path = d.file_path\n",
    "        m = Image.open(img_path)\n",
    "        r = self.augment(m)\n",
    "       \n",
    "\n",
    "        r = {\n",
    "            #'index': index,\n",
    "            'image': r,\n",
    "            'target':self.targets[index]\n",
    "        }\n",
    "        return r\n",
    "\n",
    "def null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        d[k] = [b[k] for b in batch]\n",
    "    d['image'] = torch.stack(d['image']).float()\n",
    "    d['target'] = torch.as_tensor(d['target'], dtype=torch.long)#.float()\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011484,
     "end_time": "2024-06-29T23:17:59.062869",
     "exception": false,
     "start_time": "2024-06-29T23:17:59.051385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_rgb2hsv(rgb: torch.Tensor) -> torch.Tensor:\n",
    "    cmax, cmax_idx = torch.max(rgb, dim=1, keepdim=True)\n",
    "    cmin = torch.min(rgb, dim=1, keepdim=True)[0]\n",
    "    delta = cmax - cmin\n",
    "    hsv_h = torch.empty_like(rgb[:, 0:1, :, :])\n",
    "    cmax_idx[delta == 0] = 3\n",
    "    hsv_h[cmax_idx == 0] = (((rgb[:, 1:2] - rgb[:, 2:3]) / delta) % 6)[cmax_idx == 0]\n",
    "    hsv_h[cmax_idx == 1] = (((rgb[:, 2:3] - rgb[:, 0:1]) / delta) + 2)[cmax_idx == 1]\n",
    "    hsv_h[cmax_idx == 2] = (((rgb[:, 0:1] - rgb[:, 1:2]) / delta) + 4)[cmax_idx == 2]\n",
    "    hsv_h[cmax_idx == 3] = 0.\n",
    "    hsv_h /= 6.\n",
    "    hsv_s = torch.where(cmax == 0, torch.tensor(0.).type_as(rgb), delta / cmax)\n",
    "    hsv_v = cmax\n",
    "    return torch.cat([hsv_h, hsv_s, hsv_v], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(Net, self).__init__()\n",
    "        self.output_type = ['infer', 'loss']\n",
    "        arch = CONFIG['model_name']\n",
    "\n",
    "        self.model_name = CONFIG['model_name']\n",
    "\n",
    "        self.model = timm.create_model(model_name=arch, pretrained=pretrained, in_chans=6,  num_classes=0, global_pool='')\n",
    "        #print(f'Feature channels: {self.model.feature_info}')\n",
    "        in_features =  self.model.num_features\n",
    "        self.target=nn.Linear(in_features, 2)\n",
    "\n",
    "        self.dropout = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for i in range(5)\n",
    "        ]) #droupout augmentation\n",
    "\n",
    "        self.loss_fn = SoftTargetCrossEntropy().cuda()\n",
    "    def forward(self, batch):\n",
    "        image = batch['image']\n",
    "        batch_size = len(image)\n",
    "        image = image.float()/255\n",
    "        image = torch.cat([image, F_rgb2hsv(image)],1)\n",
    "        # image = (image-self.mean)/self.std\n",
    "        x = self.model(image)\n",
    "        pool = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "\n",
    "        if self.training:\n",
    "            logit=0\n",
    "            for i in range(len(self.dropout)):\n",
    "                logit += self.target(self.dropout[i](pool))\n",
    "            logit = logit/len(self.dropout)\n",
    "        else:\n",
    "            logit = self.target(pool)\n",
    "        output = {}\n",
    "        target = batch['target']\n",
    "        \n",
    "        #output['loss'] = self.loss_fn(logit, target)\n",
    "        pred_prob = logit.softmax(dim=-1)[:, 1]\n",
    "        #print(pred_prob)\n",
    "        output['logit'] = logit\n",
    "        output['pred'] = pred_prob\n",
    "        output['pool'] = pool\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\n",
      "                           image : torch.Size([32, 3, 256, 256]) \n",
      "                          target : torch.Size([32, 1]) \n",
      "output\n",
      "                           logit : torch.Size([32, 2]) \n",
      "                            pred : torch.Size([32]) \n",
      "                            pool : torch.Size([32, 512]) \n",
      "loss\n",
      "model ok!\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------\n",
    "def run_check_net():\n",
    "\timage_size = 256\n",
    "\tbatch_size = 32\n",
    "\n",
    "\tbatch = {\n",
    "\t\t'image': torch.from_numpy(np.random.uniform(-1,1, (batch_size, 3, image_size, image_size))).float(),#.cuda(),\n",
    "\t\t'target': torch.from_numpy(np.random.choice(2, (batch_size,1))).long(),#.cuda(),\n",
    "\t}\n",
    "\n",
    "\tnet = Net(pretrained=False)#.cuda()\n",
    "\t#print(net)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\twith torch.cuda.amp.autocast(enabled=True):\n",
    "\t\t\toutput = net(batch)\n",
    "\t# ---\n",
    "\tprint('batch')\n",
    "\tfor k, v in batch.items():\n",
    "\t\tprint(f'{k:>32} : {v.shape} ')\n",
    "\n",
    "\tprint('output')\n",
    "\tfor k, v in output.items():\n",
    "\t\tif 'loss' not in k:\n",
    "\t\t\tprint(f'{k:>32} : {v.shape} ')\n",
    "\tprint('loss')\n",
    "\tfor k, v in output.items():\n",
    "\t\tif 'loss' in k:\n",
    "\t\t\tprint(f'{k:>32} : {v.item()} ')\n",
    "\n",
    "run_check_net()\n",
    "print('model ok!')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(gts, preds, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(gts)-1)\n",
    "    v_pred = np.array([1.0 - x for x in preds])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.024329,
     "end_time": "2024-06-29T23:18:00.493233",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.468904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch, mixup_fn=None):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc  = 0.0\n",
    "    if mixup_fn:\n",
    "        loss_fn = SoftTargetCrossEntropy().cuda()\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for step, data in bar:\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = data['image'].size(0)\n",
    "        if mixup_fn:\n",
    "            image = data['image']\n",
    "            ori_target = data['target']\n",
    "            \n",
    "            image, target = mixup_fn(image, ori_target)\n",
    "            data['image'] = image\n",
    "            data['target'] = target\n",
    "\n",
    "        outputs = model(data)\n",
    "        if mixup_fn:\n",
    "            loss = loss_fn(outputs['logit'], data['target'])\n",
    "            targets = ori_target\n",
    "        else:\n",
    "            loss = F.cross_entropy(outputs['logit'],  data['target'].long())\n",
    "            targets = data['target'].long()\n",
    "        pred = outputs['pred']\n",
    "        \n",
    "        gts.append(targets.squeeze().cpu().numpy().reshape(-1))\n",
    "        preds.append(pred.squeeze().detach().cpu().numpy().reshape(-1))\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        #auroc = comp_score(targets.squeeze().cpu().numpy(), preds.squeeze().detach().cpu().numpy())\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        #running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        #epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,)\n",
    "    gc.collect()\n",
    "    gts = np.concatenate(gts)\n",
    "    preds = np.concatenate(preds)\n",
    "    epoch_auroc = comp_score(gts, preds)\n",
    "    return epoch_loss, epoch_auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011634,
     "end_time": "2024-06-29T23:18:00.516892",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.505258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 0.02315,
     "end_time": "2024-06-29T23:18:00.551972",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.528822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "    preds = []\n",
    "    gts = []\n",
    "    pools = []\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = data['image'].size(0)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        loss = F.cross_entropy(outputs['logit'],  data['target'].long())\n",
    "        pred = outputs['pred']\n",
    "        targets = data['target']\n",
    "        pool = outputs['pool']\n",
    "        gts.append(targets.squeeze().cpu().numpy().reshape(-1))\n",
    "        preds.append(pred.squeeze().detach().cpu().numpy().reshape(-1))\n",
    "        pools.append(pool.squeeze().detach().cpu().numpy())\n",
    "        #auroc = comp_score(targets.squeeze().cpu().numpy(), preds.squeeze().detach().cpu().numpy())\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        #running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        #epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss)   \n",
    "    \n",
    "    gc.collect()\n",
    "    gts = np.concatenate(gts)\n",
    "    preds = np.concatenate(preds)\n",
    "    epoch_auroc = comp_score(gts, preds)\n",
    "    pools = np.vstack(pools)\n",
    "    return epoch_loss, epoch_auroc, pools, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011798,
     "end_time": "2024-06-29T23:18:00.575765",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.563967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "papermill": {
     "duration": 0.026227,
     "end_time": "2024-06-29T23:18:00.614057",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.58783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auroc = -np.inf\n",
    "    history = defaultdict(list)\n",
    "    mixup_args = {\n",
    "                'mixup_alpha': 0.5,\n",
    "                'cutmix_alpha': 0.5,\n",
    "                'cutmix_minmax': None,\n",
    "                'prob': 1.0,\n",
    "                'switch_prob': 0.5,\n",
    "                'mode': 'elem',\n",
    "                'label_smoothing': 0,\n",
    "                'num_classes': 2}\n",
    "    mixup_fn = None #Mixup(**mixup_args)\n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch, mixup_fn=mixup_fn)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_auroc, val_features, val_preds = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train AUROC'].append(train_epoch_auroc)\n",
    "        history['Valid AUROC'].append(val_epoch_auroc)\n",
    "        #history['lr'].append( scheduler.get_lr()[0] )\n",
    "        \n",
    "        # deep copy the model\n",
    "        if best_epoch_auroc <= val_epoch_auroc:\n",
    "            print(f\"Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n",
    "            best_epoch_auroc = val_epoch_auroc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(val_epoch_auroc, val_epoch_loss, epoch)\n",
    "            output_dir = CONFIG['output_dir']\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "            best_val_features = val_features\n",
    "            best_val_preds = val_preds\n",
    "        print()\n",
    "        torch.save(model.state_dict(), f'./{output_dir}/fold_{fold}_best.bin')\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history, best_val_features, best_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "papermill": {
     "duration": 0.020426,
     "end_time": "2024-06-29T23:18:00.646386",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.62596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "papermill": {
     "duration": 0.02047,
     "end_time": "2024-06-29T23:18:00.678761",
     "exception": false,
     "start_time": "2024-06-29T23:18:00.658291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(df, fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = SkinDataset(df_train, augment=make_train_augment(image_size=CONFIG['img_size']))\n",
    "    valid_dataset = SkinDataset(df_valid, augment=make_valid_augment(image_size=CONFIG['img_size']))\n",
    "    sampler = DualSampler(train_dataset, batch_size=CONFIG['train_batch_size'], sampling_rate=0.1)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True, collate_fn=null_collate,\n",
    "                             sampler=sampler)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True, collate_fn=null_collate,)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 4090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [01:19<00:00, 12.33it/s, Epoch=1, Train_Loss=0.269]\n",
      "100%|██████████| 52/52 [00:05<00:00,  8.72it/s, Epoch=1, Valid_Loss=0.25]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (-inf ---> 0.10667030051713368)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [01:18<00:00, 12.62it/s, Epoch=2, Train_Loss=0.254]\n",
      "100%|██████████| 52/52 [00:05<00:00,  8.71it/s, Epoch=2, Valid_Loss=0.258] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.10667030051713368 ---> 0.11398215963413104)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [01:23<00:00, 11.83it/s, Epoch=4, Train_Loss=0.237]\n",
      "100%|██████████| 52/52 [00:05<00:00,  9.08it/s, Epoch=4, Valid_Loss=0.227] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.115064035114955 ---> 0.12439038133580801)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [01:18<00:00, 12.60it/s, Epoch=5, Train_Loss=0.231]\n",
      "100%|██████████| 52/52 [00:05<00:00,  8.85it/s, Epoch=5, Valid_Loss=0.229] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 375/985 [00:32<00:52, 11.64it/s, Epoch=6, Train_Loss=0.229]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof = []\n",
    "for i in range(1):\n",
    "    CONFIG[\"fold\"] = i\n",
    "    train_loader, valid_loader = prepare_loaders(df, fold=CONFIG[\"fold\"])\n",
    "    model = Net(False)\n",
    "    pre_weight =torch.load(CONFIG['checkpoint_path'])\n",
    "    model.load_state_dict(pre_weight, strict=False)\n",
    "    model.cuda()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                           weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history, best_val_features, best_val_preds = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=CONFIG[\"fold\"]\n",
    "                                 )\n",
    "    \n",
    "    val_df = df[df.kfold == fold].reset_index(drop=True)[['patient_id', 'isic_id']]\n",
    "    val_features =  pd.DataFrame(best_val_features, columns=[f'cnn_features_{i}' for i in range(best_val_features.shape[1])])\n",
    "    val_df = pd.concat([val_df, val_features], axis=1)\n",
    "    val_df['preds'] = best_val_preds\n",
    "    oof.append(val_df)\n",
    "oof = pd.concat(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8940774,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5295517,
     "sourceId": 8805063,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5295538,
     "sourceId": 8805089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5295507,
     "sourceId": 8805188,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 2656,
     "sourceId": 3729,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 793.680734,
   "end_time": "2024-06-29T23:30:34.642937",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-29T23:17:20.962203",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "14f33eda98294bf7ab2c201ef8c071b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_efc119d2e1e0456fa0a6593c16a85dc2",
       "placeholder": "​",
       "style": "IPY_MODEL_f4be4b7893f14d71a8658ad521e9d4e9",
       "value": " 21.4M/21.4M [00:00&lt;00:00, 41.1MB/s]"
      }
     },
     "18bdb1a4a13e4aee9cc51601b980aca0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "244eb860d230481c85c8db4fd77fb99a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_47503710d50a4aaba66bd273e31797b0",
        "IPY_MODEL_938dc29705ca4174ab708b0e84ac456c",
        "IPY_MODEL_14f33eda98294bf7ab2c201ef8c071b0"
       ],
       "layout": "IPY_MODEL_18bdb1a4a13e4aee9cc51601b980aca0"
      }
     },
     "256368e0b8da40ffaab43806b6e7bdfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "47503710d50a4aaba66bd273e31797b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a1c7099741224d6d95e8f291dac107aa",
       "placeholder": "​",
       "style": "IPY_MODEL_e70b5a1f96bf4ddf9ac9271b3aa6ad1a",
       "value": "model.safetensors: 100%"
      }
     },
     "938dc29705ca4174ab708b0e84ac456c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c198e83f65a043f6b6886c6984bf6303",
       "max": 21355344,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_256368e0b8da40ffaab43806b6e7bdfc",
       "value": 21355344
      }
     },
     "a1c7099741224d6d95e8f291dac107aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c198e83f65a043f6b6886c6984bf6303": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e70b5a1f96bf4ddf9ac9271b3aa6ad1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "efc119d2e1e0456fa0a6593c16a85dc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4be4b7893f14d71a8658ad521e9d4e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
